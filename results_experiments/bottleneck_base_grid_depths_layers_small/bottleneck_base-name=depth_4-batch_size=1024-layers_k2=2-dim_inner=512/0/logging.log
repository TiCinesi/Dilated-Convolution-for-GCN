GraphGymModule(
  (model): DilatedPositionalGNNModel(
    (encoder): FeatureEncoder(
      (node_encoder): BottleneckEncoder(
        (embedding_list): ModuleList(
          (0): Embedding(17, 256)
          (1): Embedding(17, 256)
        )
      )
    )
    (mp): GNNDilatedPositionalStage(
      (classic_layers): ModuleList(
        (0): GeneralLayer(
          (layer): LayerGINConv(
            (model): GINConv(nn=Sequential(
              (0): Linear(256, 256, bias=True)
              (1): ReLU()
              (2): Linear(256, 256, bias=True)
            ))
          )
          (post_layer): Sequential(
            (0): ReLU()
          )
        )
      )
      (dilated_layers): ModuleList(
        (0): DilatedPositionalGeneralLayer(
          (layer): LayerGINConv(
            (model): GINConv(nn=Sequential(
              (0): Linear(256, 256, bias=True)
              (1): ReLU()
              (2): Linear(256, 256, bias=True)
            ))
          )
          (post_layer): Sequential(
            (0): ReLU()
          )
          (gem): GeM(p=3.0000, eps=1e-06)
          (pos): PositionalEncoding()
        )
        (1): DilatedPositionalGeneralLayer(
          (layer): LayerGINConv(
            (model): GINConv(nn=Sequential(
              (0): Linear(256, 256, bias=True)
              (1): ReLU()
              (2): Linear(256, 256, bias=True)
            ))
          )
          (post_layer): Sequential(
            (0): ReLU()
          )
          (gem): GeM(p=3.0000, eps=1e-06)
          (pos): PositionalEncoding()
        )
      )
      (act): ReLU()
    )
    (post_mp): BottleneckHead(
      (layer_post_mp): Linear(in_features=256, out_features=17, bias=False)
    )
  )
)
accelerator: cuda
benchmark: False
bn:
  eps: 1e-05
  mom: 0.1
cfg_dest: config.yaml
custom_metrics: []
dataset:
  cache_load: False
  cache_save: False
  dir: ./datasets
  edge_dim: 0
  edge_encoder: False
  edge_encoder_bn: False
  edge_encoder_name: Bond
  edge_message_ratio: 0.8
  edge_negative_sampling_ratio: 1.0
  edge_train_mode: all
  encoder: True
  encoder_bn: True
  encoder_dim: 128
  encoder_name: db
  format: BOTTLENECK
  label_column: none
  label_table: none
  location: local
  name: depth_4
  node_encoder: True
  node_encoder_bn: False
  node_encoder_name: bottleneck_encoder
  positional_encoding_path: False
  preprocesss_dataset: True
  remove_feature: False
  resample_disjoint: False
  resample_negative: False
  shuffle_split: True
  split: [0.8, 0.1, 0.1]
  split_mode: random
  task: graph
  task_type: classification
  to_undirected: False
  transductive: False
  transform: none
  tu_simple: True
  use_sparse_adj: False
devices: None
gnn:
  act: relu
  act_on_last_layer_mp: True
  agg: none
  att_final_linear: False
  att_final_linear_bn: False
  att_heads: 4
  att_heads_final: 6
  batchnorm: False
  clear_feature: True
  dilated_path_join: add
  dim_inner: 256
  dropout: 0.0
  edge_agg: add
  head: bottleneck_head
  keep_edge: 0.5
  l2norm: False
  layer_norm: True
  layer_type: ginconv_paper
  layer_type_dilated: ginconv_paper
  layers_k1: 1
  layers_k2: 2
  layers_mp: 3
  layers_post_mp: 1
  layers_pre_mp: 0
  learn_alpha_residual_connection: True
  msg_direction: single
  normalize_adj: False
  self_msg: concat
  skip_every: 1
  stage_type: skipsum
  use_edge_features: False
gpu_mem: False
mem:
  inplace: False
metric_agg: argmax
metric_best: accuracy
model:
  edge_decoding: dot
  graph_pooling: mean
  loss_fun: cross_entropy
  match_upper: True
  size_average: mean
  thresh: 0.5
  type: dilapos_gnn
num_threads: 6
num_workers: 16
optim:
  base_lr: 0.001
  lr_decay: 0.1
  max_epoch: 100
  momentum: 0.9
  optimizer: adam
  scheduler: reduce_lr_on_plateau
  step_gamma: 0.5
  step_size: 10
  steps: [30, 60, 90]
  weight_decay: 0.0
out_dir: results_experiments/bottleneck_base_grid_depths_layers_small/bottleneck_base-name=depth_4-batch_size=1024-layers_k2=2-dim_inner=512
persistent_workers: False
print: both
round: 4
run_dir: results_experiments/bottleneck_base_grid_depths_layers_small/bottleneck_base-name=depth_4-batch_size=1024-layers_k2=2-dim_inner=512/0
seed: 1
share:
  dim0: 16
  dim_in: 2
  dim_out: 16
  num_splits: 2
tensorboard_agg: True
tensorboard_each_run: False
train:
  accumulate_grad: 1
  auto_resume: False
  batch_size: 1024
  ckpt_clean: True
  ckpt_period: 100
  compute_test: False
  early_stopping: True
  early_stopping_patience: 50
  enable_ckpt: True
  epoch_resume: -1
  eval_period: 1
  iter_per_epoch: 32
  monitor_val: False
  neighbor_sizes: [20, 15, 10, 5]
  node_per_graph: 32
  radius: extend
  sample_node: False
  sampler: full_batch
  skip_train_eval: False
  walk_length: 4
train_strategy: None
val:
  node_per_graph: 32
  radius: extend
  sample_node: False
  sampler: full_batch
view_emb: False
Num parameters: 407812
val: {'epoch': 0, 'loss': 2.8563, 'lr': 0.001, 'params': 407812, 'time_iter': 0.4793, 'accuracy': 0.0309}
train: {'epoch': 0, 'eta': 2880620.3752, 'loss': 2.7788, 'lr': 0.001, 'params': 407812, 'time_iter': 23.2777, 'accuracy': 0.0761}
val: {'epoch': 1, 'loss': 3.9719, 'lr': 0.001, 'params': 407812, 'time_iter': 0.6798, 'accuracy': 0.0006}
train: {'epoch': 1, 'eta': 2861324.4369, 'loss': 2.7201, 'lr': 0.001, 'params': 407812, 'time_iter': 23.4378, 'accuracy': 0.0878}
val: {'epoch': 2, 'loss': 2.8622, 'lr': 0.001, 'params': 407812, 'time_iter': 0.6531, 'accuracy': 0.2125}
train: {'epoch': 2, 'eta': 2830080.4582, 'loss': 2.0531, 'lr': 0.001, 'params': 407812, 'time_iter': 23.3071, 'accuracy': 0.287}
val: {'epoch': 3, 'loss': 7.1192, 'lr': 0.001, 'params': 407812, 'time_iter': 0.5248, 'accuracy': 0.2172}
train: {'epoch': 3, 'eta': 2797791.4555, 'loss': 1.1914, 'lr': 0.001, 'params': 407812, 'time_iter': 23.2371, 'accuracy': 0.5519}
val: {'epoch': 4, 'loss': 12.1389, 'lr': 0.001, 'params': 407812, 'time_iter': 0.4923, 'accuracy': 0.2184}
train: {'epoch': 4, 'eta': 2767902.8715, 'loss': 0.5151, 'lr': 0.001, 'params': 407812, 'time_iter': 23.2836, 'accuracy': 0.7965}
val: {'epoch': 5, 'loss': 12.6351, 'lr': 0.001, 'params': 407812, 'time_iter': 0.5194, 'accuracy': 0.2203}
train: {'epoch': 5, 'eta': 2739659.7642, 'loss': 0.3773, 'lr': 0.001, 'params': 407812, 'time_iter': 23.3542, 'accuracy': 0.8512}
val: {'epoch': 6, 'loss': 13.8507, 'lr': 0.001, 'params': 407812, 'time_iter': 0.5096, 'accuracy': 0.2216}
train: {'epoch': 6, 'eta': 2701992.3645, 'loss': 0.3117, 'lr': 0.001, 'params': 407812, 'time_iter': 22.8031, 'accuracy': 0.8711}
val: {'epoch': 7, 'loss': 14.1056, 'lr': 0.001, 'params': 407812, 'time_iter': 0.5192, 'accuracy': 0.2188}
train: {'epoch': 7, 'eta': 2668130.0254, 'loss': 0.2928, 'lr': 0.001, 'params': 407812, 'time_iter': 22.9084, 'accuracy': 0.8746}
val: {'epoch': 8, 'loss': 14.3042, 'lr': 0.001, 'params': 407812, 'time_iter': 0.5064, 'accuracy': 0.22}
train: {'epoch': 8, 'eta': 2637188.2076, 'loss': 0.2879, 'lr': 0.001, 'params': 407812, 'time_iter': 23.0476, 'accuracy': 0.8748}
val: {'epoch': 9, 'loss': 10.4791, 'lr': 0.001, 'params': 407812, 'time_iter': 0.5111, 'accuracy': 0.2234}
train: {'epoch': 9, 'eta': 2603529.3684, 'loss': 0.3248, 'lr': 0.001, 'params': 407812, 'time_iter': 22.7682, 'accuracy': 0.8653}
val: {'epoch': 10, 'loss': 13.9047, 'lr': 0.001, 'params': 407812, 'time_iter': 0.5138, 'accuracy': 0.2147}
train: {'epoch': 10, 'eta': 2572049.496, 'loss': 0.2411, 'lr': 0.001, 'params': 407812, 'time_iter': 22.8902, 'accuracy': 0.8859}
val: {'epoch': 11, 'loss': 13.6566, 'lr': 0.001, 'params': 407812, 'time_iter': 0.619, 'accuracy': 0.2272}
train: {'epoch': 11, 'eta': 2543051.7501, 'loss': 0.2806, 'lr': 0.001, 'params': 407812, 'time_iter': 23.1088, 'accuracy': 0.8738}
val: {'epoch': 12, 'loss': 11.4986, 'lr': 0.001, 'params': 407812, 'time_iter': 0.6132, 'accuracy': 0.23}
train: {'epoch': 12, 'eta': 2510937.9389, 'loss': 0.2848, 'lr': 0.001, 'params': 407812, 'time_iter': 22.7343, 'accuracy': 0.8723}
val: {'epoch': 13, 'loss': 14.0778, 'lr': 0.001, 'params': 407812, 'time_iter': 0.6201, 'accuracy': 0.2216}
train: {'epoch': 13, 'eta': 2478622.5184, 'loss': 0.229, 'lr': 0.001, 'params': 407812, 'time_iter': 22.6393, 'accuracy': 0.8868}
val: {'epoch': 14, 'loss': 14.1373, 'lr': 0.001, 'params': 407812, 'time_iter': 0.5216, 'accuracy': 0.2228}
train: {'epoch': 14, 'eta': 2448562.8955, 'loss': 0.2579, 'lr': 0.001, 'params': 407812, 'time_iter': 22.8821, 'accuracy': 0.8779}
val: {'epoch': 15, 'loss': 13.5851, 'lr': 0.001, 'params': 407812, 'time_iter': 0.5153, 'accuracy': 0.2238}
train: {'epoch': 15, 'eta': 2418881.0435, 'loss': 0.2653, 'lr': 0.001, 'params': 407812, 'time_iter': 22.9119, 'accuracy': 0.8767}
val: {'epoch': 16, 'loss': 13.5248, 'lr': 0.001, 'params': 407812, 'time_iter': 0.5161, 'accuracy': 0.2325}
train: {'epoch': 16, 'eta': 2386716.9286, 'loss': 0.2526, 'lr': 0.001, 'params': 407812, 'time_iter': 22.4851, 'accuracy': 0.8785}
val: {'epoch': 17, 'loss': 13.4067, 'lr': 0.001, 'params': 407812, 'time_iter': 0.5353, 'accuracy': 0.2303}
train: {'epoch': 17, 'eta': 2361552.3031, 'loss': 0.2532, 'lr': 0.001, 'params': 407812, 'time_iter': 23.6351, 'accuracy': 0.8775}
val: {'epoch': 18, 'loss': 9.1239, 'lr': 0.001, 'params': 407812, 'time_iter': 0.5178, 'accuracy': 0.2288}
train: {'epoch': 18, 'eta': 2332037.5609, 'loss': 0.2892, 'lr': 0.001, 'params': 407812, 'time_iter': 22.9053, 'accuracy': 0.8679}
val: {'epoch': 19, 'loss': 12.3292, 'lr': 0.001, 'params': 407812, 'time_iter': 0.5568, 'accuracy': 0.2309}
train: {'epoch': 19, 'eta': 2303529.3072, 'loss': 0.3585, 'lr': 0.001, 'params': 407812, 'time_iter': 23.0889, 'accuracy': 0.8235}
val: {'epoch': 20, 'loss': 10.5998, 'lr': 0.001, 'params': 407812, 'time_iter': 0.5192, 'accuracy': 0.2225}
train: {'epoch': 20, 'eta': 2275138.1504, 'loss': 0.3748, 'lr': 0.001, 'params': 407812, 'time_iter': 23.121, 'accuracy': 0.8178}
val: {'epoch': 21, 'loss': 12.4477, 'lr': 0.001, 'params': 407812, 'time_iter': 0.6136, 'accuracy': 0.2328}
train: {'epoch': 21, 'eta': 2246844.7955, 'loss': 0.3649, 'lr': 0.001, 'params': 407812, 'time_iter': 23.1535, 'accuracy': 0.8183}
val: {'epoch': 22, 'loss': 13.0052, 'lr': 0.001, 'params': 407812, 'time_iter': 0.6153, 'accuracy': 0.2222}
train: {'epoch': 22, 'eta': 2217339.474, 'loss': 0.3389, 'lr': 0.001, 'params': 407812, 'time_iter': 22.8774, 'accuracy': 0.8251}
val: {'epoch': 23, 'loss': 12.9435, 'lr': 0.001, 'params': 407812, 'time_iter': 0.6222, 'accuracy': 0.2291}
train: {'epoch': 23, 'eta': 2187562.4239, 'loss': 0.3602, 'lr': 0.001, 'params': 407812, 'time_iter': 22.7896, 'accuracy': 0.8189}
val: {'epoch': 24, 'loss': 14.1532, 'lr': 0.001, 'params': 407812, 'time_iter': 0.61, 'accuracy': 0.2325}
train: {'epoch': 24, 'eta': 2159406.3323, 'loss': 0.3083, 'lr': 0.001, 'params': 407812, 'time_iter': 23.1943, 'accuracy': 0.8513}
val: {'epoch': 25, 'loss': 15.4297, 'lr': 0.0005, 'params': 407812, 'time_iter': 0.5516, 'accuracy': 0.235}
train: {'epoch': 25, 'eta': 2133170.2326, 'loss': 0.1935, 'lr': 0.0005, 'params': 407812, 'time_iter': 23.7521, 'accuracy': 0.8877}
val: {'epoch': 26, 'loss': 15.6986, 'lr': 0.0005, 'params': 407812, 'time_iter': 0.5063, 'accuracy': 0.2278}
train: {'epoch': 26, 'eta': 2103669.7541, 'loss': 0.1972, 'lr': 0.0005, 'params': 407812, 'time_iter': 22.8619, 'accuracy': 0.8866}
val: {'epoch': 27, 'loss': 16.1042, 'lr': 0.0005, 'params': 407812, 'time_iter': 0.5118, 'accuracy': 0.2306}
train: {'epoch': 27, 'eta': 2077048.9871, 'loss': 0.195, 'lr': 0.0005, 'params': 407812, 'time_iter': 23.7373, 'accuracy': 0.8874}
val: {'epoch': 28, 'loss': 16.266, 'lr': 0.0005, 'params': 407812, 'time_iter': 0.5407, 'accuracy': 0.2309}
train: {'epoch': 28, 'eta': 2046898.6588, 'loss': 0.199, 'lr': 0.0005, 'params': 407812, 'time_iter': 22.6527, 'accuracy': 0.8862}
val: {'epoch': 29, 'loss': 16.1766, 'lr': 0.0005, 'params': 407812, 'time_iter': 0.5057, 'accuracy': 0.2247}
train: {'epoch': 29, 'eta': 2017604.3033, 'loss': 0.1907, 'lr': 0.0005, 'params': 407812, 'time_iter': 22.9043, 'accuracy': 0.8876}
val: {'epoch': 30, 'loss': 16.3699, 'lr': 0.0005, 'params': 407812, 'time_iter': 0.5743, 'accuracy': 0.2347}
train: {'epoch': 30, 'eta': 1988391.8666, 'loss': 0.203, 'lr': 0.0005, 'params': 407812, 'time_iter': 22.9183, 'accuracy': 0.8847}
val: {'epoch': 31, 'loss': 16.3699, 'lr': 0.0005, 'params': 407812, 'time_iter': 0.5163, 'accuracy': 0.2291}
train: {'epoch': 31, 'eta': 1962701.8896, 'loss': 0.1892, 'lr': 0.0005, 'params': 407812, 'time_iter': 24.2312, 'accuracy': 0.8875}
val: {'epoch': 32, 'loss': 16.8628, 'lr': 0.0005, 'params': 407812, 'time_iter': 0.5369, 'accuracy': 0.2306}
train: {'epoch': 32, 'eta': 1934369.5026, 'loss': 0.1992, 'lr': 0.0005, 'params': 407812, 'time_iter': 23.2998, 'accuracy': 0.8859}
val: {'epoch': 33, 'loss': 16.4962, 'lr': 0.0005, 'params': 407812, 'time_iter': 0.5914, 'accuracy': 0.2275}
train: {'epoch': 33, 'eta': 1904843.4389, 'loss': 0.1885, 'lr': 0.0005, 'params': 407812, 'time_iter': 22.8271, 'accuracy': 0.8878}
val: {'epoch': 34, 'loss': 16.5391, 'lr': 0.0005, 'params': 407812, 'time_iter': 0.5899, 'accuracy': 0.2328}
train: {'epoch': 34, 'eta': 1874796.2924, 'loss': 0.2003, 'lr': 0.0005, 'params': 407812, 'time_iter': 22.5782, 'accuracy': 0.8851}
val: {'epoch': 35, 'loss': 16.6114, 'lr': 0.0005, 'params': 407812, 'time_iter': 0.5912, 'accuracy': 0.2288}
train: {'epoch': 35, 'eta': 1844765.4258, 'loss': 0.1875, 'lr': 0.0005, 'params': 407812, 'time_iter': 22.5399, 'accuracy': 0.8878}
val: {'epoch': 36, 'loss': 16.8843, 'lr': 0.0005, 'params': 407812, 'time_iter': 0.5158, 'accuracy': 0.2328}
train: {'epoch': 36, 'eta': 1815933.5953, 'loss': 0.199, 'lr': 0.0005, 'params': 407812, 'time_iter': 23.0561, 'accuracy': 0.8851}
val: {'epoch': 37, 'loss': 17.5447, 'lr': 0.0003, 'params': 407812, 'time_iter': 0.5026, 'accuracy': 0.2309}
train: {'epoch': 37, 'eta': 1786379.0603, 'loss': 0.1829, 'lr': 0.0003, 'params': 407812, 'time_iter': 22.7014, 'accuracy': 0.8874}
val: {'epoch': 38, 'loss': 17.5708, 'lr': 0.0003, 'params': 407812, 'time_iter': 0.5297, 'accuracy': 0.2325}
train: {'epoch': 38, 'eta': 1757648.0173, 'loss': 0.1828, 'lr': 0.0003, 'params': 407812, 'time_iter': 23.0917, 'accuracy': 0.8876}
val: {'epoch': 39, 'loss': 17.6547, 'lr': 0.0003, 'params': 407812, 'time_iter': 0.506, 'accuracy': 0.2316}
train: {'epoch': 39, 'eta': 1728353.3902, 'loss': 0.1831, 'lr': 0.0003, 'params': 407812, 'time_iter': 22.7947, 'accuracy': 0.8875}
val: {'epoch': 40, 'loss': 17.873, 'lr': 0.0003, 'params': 407812, 'time_iter': 0.5205, 'accuracy': 0.2316}
train: {'epoch': 40, 'eta': 1698288.5422, 'loss': 0.1847, 'lr': 0.0003, 'params': 407812, 'time_iter': 22.3448, 'accuracy': 0.8871}
Results aggregated across runs saved in results_experiments/bottleneck_base_grid_depths_layers_small/bottleneck_base-name=depth_4-batch_size=1024-layers_k2=2-dim_inner=512/agg
