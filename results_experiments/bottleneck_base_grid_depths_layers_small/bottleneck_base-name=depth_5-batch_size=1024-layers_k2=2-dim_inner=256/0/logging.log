GraphGymModule(
  (model): DilatedPositionalGNNModel(
    (encoder): FeatureEncoder(
      (node_encoder): BottleneckEncoder(
        (embedding_list): ModuleList(
          (0): Embedding(33, 256)
          (1): Embedding(33, 256)
        )
      )
    )
    (mp): GNNDilatedPositionalStage(
      (classic_layers): ModuleList(
        (0): GeneralLayer(
          (layer): LayerGINConv(
            (model): GINConv(nn=Sequential(
              (0): Linear(256, 256, bias=True)
              (1): ReLU()
              (2): Linear(256, 256, bias=True)
            ))
          )
          (post_layer): Sequential(
            (0): ReLU()
          )
        )
      )
      (dilated_layers): ModuleList(
        (0): DilatedPositionalGeneralLayer(
          (layer): LayerGINConv(
            (model): GINConv(nn=Sequential(
              (0): Linear(256, 256, bias=True)
              (1): ReLU()
              (2): Linear(256, 256, bias=True)
            ))
          )
          (post_layer): Sequential(
            (0): ReLU()
          )
          (gem): GeM(p=3.0000, eps=1e-06)
          (pos): PositionalEncoding()
        )
        (1): DilatedPositionalGeneralLayer(
          (layer): LayerGINConv(
            (model): GINConv(nn=Sequential(
              (0): Linear(256, 256, bias=True)
              (1): ReLU()
              (2): Linear(256, 256, bias=True)
            ))
          )
          (post_layer): Sequential(
            (0): ReLU()
          )
          (gem): GeM(p=3.0000, eps=1e-06)
          (pos): PositionalEncoding()
        )
      )
      (act): ReLU()
    )
    (post_mp): BottleneckHead(
      (layer_post_mp): Linear(in_features=256, out_features=33, bias=False)
    )
  )
)
accelerator: cuda
benchmark: False
bn:
  eps: 1e-05
  mom: 0.1
cfg_dest: config.yaml
custom_metrics: []
dataset:
  cache_load: False
  cache_save: False
  dir: ./datasets
  edge_dim: 0
  edge_encoder: False
  edge_encoder_bn: False
  edge_encoder_name: Bond
  edge_message_ratio: 0.8
  edge_negative_sampling_ratio: 1.0
  edge_train_mode: all
  encoder: True
  encoder_bn: True
  encoder_dim: 128
  encoder_name: db
  format: BOTTLENECK
  label_column: none
  label_table: none
  location: local
  name: depth_5
  node_encoder: True
  node_encoder_bn: False
  node_encoder_name: bottleneck_encoder
  positional_encoding_path: False
  preprocesss_dataset: True
  remove_feature: False
  resample_disjoint: False
  resample_negative: False
  shuffle_split: True
  split: [0.8, 0.1, 0.1]
  split_mode: random
  task: graph
  task_type: classification
  to_undirected: False
  transductive: False
  transform: none
  tu_simple: True
  use_sparse_adj: False
devices: None
gnn:
  act: relu
  act_on_last_layer_mp: True
  agg: none
  att_final_linear: False
  att_final_linear_bn: False
  att_heads: 4
  att_heads_final: 6
  batchnorm: False
  clear_feature: True
  dilated_path_join: add
  dim_inner: 256
  dropout: 0.0
  edge_agg: add
  head: bottleneck_head
  keep_edge: 0.5
  l2norm: False
  layer_norm: True
  layer_type: ginconv_paper
  layer_type_dilated: ginconv_paper
  layers_k1: 1
  layers_k2: 2
  layers_mp: 3
  layers_post_mp: 1
  layers_pre_mp: 0
  learn_alpha_residual_connection: True
  msg_direction: single
  normalize_adj: False
  self_msg: concat
  skip_every: 1
  stage_type: skipsum
  use_edge_features: False
gpu_mem: False
mem:
  inplace: False
metric_agg: argmax
metric_best: accuracy
model:
  edge_decoding: dot
  graph_pooling: mean
  loss_fun: cross_entropy
  match_upper: True
  size_average: mean
  thresh: 0.5
  type: dilapos_gnn
num_threads: 6
num_workers: 16
optim:
  base_lr: 0.001
  lr_decay: 0.1
  max_epoch: 100
  momentum: 0.9
  optimizer: adam
  scheduler: reduce_lr_on_plateau
  step_gamma: 0.5
  step_size: 10
  steps: [30, 60, 90]
  weight_decay: 0.0
out_dir: results_experiments/bottleneck_base_grid_depths_layers_small/bottleneck_base-name=depth_5-batch_size=1024-layers_k2=2-dim_inner=256
persistent_workers: False
print: both
round: 4
run_dir: results_experiments/bottleneck_base_grid_depths_layers_small/bottleneck_base-name=depth_5-batch_size=1024-layers_k2=2-dim_inner=256/0
seed: 1
share:
  dim0: 32
  dim_in: 2
  dim_out: 32
  num_splits: 2
tensorboard_agg: True
tensorboard_each_run: False
train:
  accumulate_grad: 1
  auto_resume: False
  batch_size: 1024
  ckpt_clean: True
  ckpt_period: 100
  compute_test: False
  early_stopping: True
  early_stopping_patience: 50
  enable_ckpt: True
  epoch_resume: -1
  eval_period: 1
  iter_per_epoch: 32
  monitor_val: False
  neighbor_sizes: [20, 15, 10, 5]
  node_per_graph: 32
  radius: extend
  sample_node: False
  sampler: full_batch
  skip_train_eval: False
  walk_length: 4
train_strategy: None
val:
  node_per_graph: 32
  radius: extend
  sample_node: False
  sampler: full_batch
view_emb: False
Num parameters: 420100
val: {'epoch': 0, 'loss': 3.512, 'lr': 0.001, 'params': 420100, 'time_iter': 0.8654, 'accuracy': 0.0225}
train: {'epoch': 0, 'eta': 24061178.9167, 'loss': 3.4684, 'lr': 0.001, 'params': 420100, 'time_iter': 97.2169, 'accuracy': 0.0422}
val: {'epoch': 1, 'loss': 4.7239, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7456, 'accuracy': 0.0409}
train: {'epoch': 1, 'eta': 23508334.5095, 'loss': 3.1957, 'lr': 0.001, 'params': 420100, 'time_iter': 94.6879, 'accuracy': 0.1052}
val: {'epoch': 2, 'loss': 8.8983, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7554, 'accuracy': 0.0389}
train: {'epoch': 2, 'eta': 23062484.1199, 'loss': 2.2378, 'lr': 0.001, 'params': 420100, 'time_iter': 93.4043, 'accuracy': 0.3176}
val: {'epoch': 3, 'loss': 13.5504, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7141, 'accuracy': 0.0405}
train: {'epoch': 3, 'eta': 22732168.838, 'loss': 1.7748, 'lr': 0.001, 'params': 420100, 'time_iter': 93.5604, 'accuracy': 0.4426}
val: {'epoch': 4, 'loss': 16.7365, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7438, 'accuracy': 0.0391}
train: {'epoch': 4, 'eta': 22204286.9307, 'loss': 1.5452, 'lr': 0.001, 'params': 420100, 'time_iter': 88.5892, 'accuracy': 0.5134}
val: {'epoch': 5, 'loss': 20.0192, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7315, 'accuracy': 0.0419}
train: {'epoch': 5, 'eta': 21755325.9566, 'loss': 1.3981, 'lr': 0.001, 'params': 420100, 'time_iter': 87.9965, 'accuracy': 0.5599}
val: {'epoch': 6, 'loss': 20.2532, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7278, 'accuracy': 0.0433}
train: {'epoch': 6, 'eta': 21361405.4954, 'loss': 1.3069, 'lr': 0.001, 'params': 420100, 'time_iter': 87.684, 'accuracy': 0.5898}
val: {'epoch': 7, 'loss': 23.7196, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7272, 'accuracy': 0.0427}
train: {'epoch': 7, 'eta': 21055965.6532, 'loss': 1.2231, 'lr': 0.001, 'params': 420100, 'time_iter': 89.2423, 'accuracy': 0.6157}
val: {'epoch': 8, 'loss': 25.5131, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7367, 'accuracy': 0.042}
train: {'epoch': 8, 'eta': 20739060.2141, 'loss': 1.1672, 'lr': 0.001, 'params': 420100, 'time_iter': 88.0649, 'accuracy': 0.6345}
val: {'epoch': 9, 'loss': 26.9638, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7628, 'accuracy': 0.0416}
train: {'epoch': 9, 'eta': 20486014.3021, 'loss': 1.1, 'lr': 0.001, 'params': 420100, 'time_iter': 90.0432, 'accuracy': 0.6562}
val: {'epoch': 10, 'loss': 31.784, 'lr': 0.001, 'params': 420100, 'time_iter': 0.9216, 'accuracy': 0.0408}
train: {'epoch': 10, 'eta': 20218870.9298, 'loss': 1.0444, 'lr': 0.001, 'params': 420100, 'time_iter': 89.0951, 'accuracy': 0.6748}
val: {'epoch': 11, 'loss': 31.3226, 'lr': 0.001, 'params': 420100, 'time_iter': 0.9313, 'accuracy': 0.0414}
train: {'epoch': 11, 'eta': 19964101.0605, 'loss': 1.0237, 'lr': 0.001, 'params': 420100, 'time_iter': 89.3663, 'accuracy': 0.6824}
val: {'epoch': 12, 'loss': 30.7079, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7447, 'accuracy': 0.0442}
train: {'epoch': 12, 'eta': 19699335.669, 'loss': 0.9678, 'lr': 0.001, 'params': 420100, 'time_iter': 88.4806, 'accuracy': 0.7}
val: {'epoch': 13, 'loss': 36.7776, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7236, 'accuracy': 0.0448}
train: {'epoch': 13, 'eta': 19434066.206, 'loss': 0.9032, 'lr': 0.001, 'params': 420100, 'time_iter': 88.0425, 'accuracy': 0.7211}
val: {'epoch': 14, 'loss': 35.8364, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7884, 'accuracy': 0.0436}
train: {'epoch': 14, 'eta': 19176240.7166, 'loss': 0.9073, 'lr': 0.001, 'params': 420100, 'time_iter': 88.1429, 'accuracy': 0.722}
val: {'epoch': 15, 'loss': 38.9064, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7245, 'accuracy': 0.0444}
train: {'epoch': 15, 'eta': 18902682.0167, 'loss': 0.8549, 'lr': 0.001, 'params': 420100, 'time_iter': 86.5874, 'accuracy': 0.7385}
val: {'epoch': 16, 'loss': 41.7651, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7353, 'accuracy': 0.0442}
train: {'epoch': 16, 'eta': 18643221.5463, 'loss': 0.8146, 'lr': 0.001, 'params': 420100, 'time_iter': 87.1921, 'accuracy': 0.7519}
val: {'epoch': 17, 'loss': 38.8165, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7059, 'accuracy': 0.0441}
train: {'epoch': 17, 'eta': 18413239.0646, 'loss': 0.8037, 'lr': 0.001, 'params': 420100, 'time_iter': 89.3757, 'accuracy': 0.7566}
val: {'epoch': 18, 'loss': 47.8023, 'lr': 0.001, 'params': 420100, 'time_iter': 0.8493, 'accuracy': 0.0441}
train: {'epoch': 18, 'eta': 18157209.7101, 'loss': 0.7501, 'lr': 0.001, 'params': 420100, 'time_iter': 86.8672, 'accuracy': 0.7741}
val: {'epoch': 19, 'loss': 40.6514, 'lr': 0.001, 'params': 420100, 'time_iter': 0.824, 'accuracy': 0.0456}
train: {'epoch': 19, 'eta': 17919870.9256, 'loss': 0.7794, 'lr': 0.001, 'params': 420100, 'time_iter': 88.3477, 'accuracy': 0.7665}
val: {'epoch': 20, 'loss': 44.9855, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7116, 'accuracy': 0.0461}
train: {'epoch': 20, 'eta': 17680822.0844, 'loss': 0.7183, 'lr': 0.001, 'params': 420100, 'time_iter': 87.9991, 'accuracy': 0.7838}
val: {'epoch': 21, 'loss': 48.836, 'lr': 0.001, 'params': 420100, 'time_iter': 0.724, 'accuracy': 0.0464}
train: {'epoch': 21, 'eta': 17432477.2294, 'loss': 0.7065, 'lr': 0.001, 'params': 420100, 'time_iter': 86.7549, 'accuracy': 0.789}
val: {'epoch': 22, 'loss': 51.5495, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7119, 'accuracy': 0.0458}
train: {'epoch': 22, 'eta': 17203970.1324, 'loss': 0.6885, 'lr': 0.001, 'params': 420100, 'time_iter': 88.7983, 'accuracy': 0.7958}
val: {'epoch': 23, 'loss': 51.8031, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7257, 'accuracy': 0.047}
train: {'epoch': 23, 'eta': 16971665.828, 'loss': 0.6759, 'lr': 0.001, 'params': 420100, 'time_iter': 88.2501, 'accuracy': 0.7987}
val: {'epoch': 24, 'loss': 51.6369, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7161, 'accuracy': 0.0427}
train: {'epoch': 24, 'eta': 16734380.8938, 'loss': 0.6617, 'lr': 0.001, 'params': 420100, 'time_iter': 87.4614, 'accuracy': 0.8012}
val: {'epoch': 25, 'loss': 58.8315, 'lr': 0.001, 'params': 420100, 'time_iter': 0.8461, 'accuracy': 0.0447}
train: {'epoch': 25, 'eta': 16508341.7283, 'loss': 0.6208, 'lr': 0.001, 'params': 420100, 'time_iter': 88.8405, 'accuracy': 0.8198}
val: {'epoch': 26, 'loss': 59.9312, 'lr': 0.001, 'params': 420100, 'time_iter': 0.8377, 'accuracy': 0.0427}
train: {'epoch': 26, 'eta': 16274895.868, 'loss': 0.6302, 'lr': 0.001, 'params': 420100, 'time_iter': 87.7015, 'accuracy': 0.8146}
val: {'epoch': 27, 'loss': 62.7637, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7182, 'accuracy': 0.0445}
train: {'epoch': 27, 'eta': 16046837.0934, 'loss': 0.6053, 'lr': 0.001, 'params': 420100, 'time_iter': 88.3818, 'accuracy': 0.8228}
val: {'epoch': 28, 'loss': 59.1464, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7084, 'accuracy': 0.0452}
train: {'epoch': 28, 'eta': 15810892.4024, 'loss': 0.6302, 'lr': 0.001, 'params': 420100, 'time_iter': 87.0134, 'accuracy': 0.8187}
val: {'epoch': 29, 'loss': 56.3141, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7104, 'accuracy': 0.047}
train: {'epoch': 29, 'eta': 15569624.2765, 'loss': 0.5841, 'lr': 0.001, 'params': 420100, 'time_iter': 85.8904, 'accuracy': 0.8304}
val: {'epoch': 30, 'loss': 62.5834, 'lr': 0.001, 'params': 420100, 'time_iter': 0.713, 'accuracy': 0.0441}
train: {'epoch': 30, 'eta': 15343152.0693, 'loss': 0.5784, 'lr': 0.001, 'params': 420100, 'time_iter': 88.2416, 'accuracy': 0.8296}
val: {'epoch': 31, 'loss': 61.0663, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7032, 'accuracy': 0.0448}
train: {'epoch': 31, 'eta': 15112287.4064, 'loss': 0.5854, 'lr': 0.001, 'params': 420100, 'time_iter': 87.3458, 'accuracy': 0.8318}
val: {'epoch': 32, 'loss': 64.8056, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7378, 'accuracy': 0.0452}
train: {'epoch': 32, 'eta': 14881138.3177, 'loss': 0.5489, 'lr': 0.001, 'params': 420100, 'time_iter': 87.1405, 'accuracy': 0.8433}
val: {'epoch': 33, 'loss': 63.7748, 'lr': 0.001, 'params': 420100, 'time_iter': 0.8354, 'accuracy': 0.0427}
train: {'epoch': 33, 'eta': 14647138.1052, 'loss': 0.5602, 'lr': 0.001, 'params': 420100, 'time_iter': 86.3918, 'accuracy': 0.8416}
val: {'epoch': 34, 'loss': 73.2073, 'lr': 0.001, 'params': 420100, 'time_iter': 0.847, 'accuracy': 0.0423}
train: {'epoch': 34, 'eta': 14414564.9, 'loss': 0.5165, 'lr': 0.001, 'params': 420100, 'time_iter': 86.4774, 'accuracy': 0.8507}
val: {'epoch': 35, 'loss': 74.5261, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7295, 'accuracy': 0.0452}
train: {'epoch': 35, 'eta': 14186246.094, 'loss': 0.5186, 'lr': 0.001, 'params': 420100, 'time_iter': 87.2299, 'accuracy': 0.8514}
val: {'epoch': 36, 'loss': 70.3606, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7519, 'accuracy': 0.0434}
train: {'epoch': 36, 'eta': 13959691.5789, 'loss': 0.5373, 'lr': 0.001, 'params': 420100, 'time_iter': 87.5142, 'accuracy': 0.8498}
val: {'epoch': 37, 'loss': 63.3655, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7234, 'accuracy': 0.0455}
train: {'epoch': 37, 'eta': 13728329.5637, 'loss': 0.5677, 'lr': 0.001, 'params': 420100, 'time_iter': 86.2354, 'accuracy': 0.8405}
val: {'epoch': 38, 'loss': 79.7863, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7005, 'accuracy': 0.0458}
train: {'epoch': 38, 'eta': 13498475.9277, 'loss': 0.4542, 'lr': 0.001, 'params': 420100, 'time_iter': 86.4143, 'accuracy': 0.8757}
val: {'epoch': 39, 'loss': 70.5393, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7207, 'accuracy': 0.0455}
train: {'epoch': 39, 'eta': 13270110.6092, 'loss': 0.5427, 'lr': 0.001, 'params': 420100, 'time_iter': 86.6269, 'accuracy': 0.8498}
val: {'epoch': 40, 'loss': 70.4094, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7138, 'accuracy': 0.0431}
train: {'epoch': 40, 'eta': 13042008.8712, 'loss': 0.4867, 'lr': 0.001, 'params': 420100, 'time_iter': 86.5402, 'accuracy': 0.8663}
val: {'epoch': 41, 'loss': 81.9469, 'lr': 0.001, 'params': 420100, 'time_iter': 0.8281, 'accuracy': 0.0456}
train: {'epoch': 41, 'eta': 12816186.1476, 'loss': 0.4656, 'lr': 0.001, 'params': 420100, 'time_iter': 87.0382, 'accuracy': 0.8691}
val: {'epoch': 42, 'loss': 76.7491, 'lr': 0.001, 'params': 420100, 'time_iter': 0.8272, 'accuracy': 0.0452}
train: {'epoch': 42, 'eta': 12593628.8013, 'loss': 0.4947, 'lr': 0.001, 'params': 420100, 'time_iter': 87.9081, 'accuracy': 0.8641}
val: {'epoch': 43, 'loss': 84.3875, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7243, 'accuracy': 0.0445}
train: {'epoch': 43, 'eta': 12367185.997, 'loss': 0.4447, 'lr': 0.001, 'params': 420100, 'time_iter': 86.6472, 'accuracy': 0.8785}
val: {'epoch': 44, 'loss': 78.7961, 'lr': 0.001, 'params': 420100, 'time_iter': 0.8197, 'accuracy': 0.045}
train: {'epoch': 44, 'eta': 12147010.3733, 'loss': 0.4961, 'lr': 0.001, 'params': 420100, 'time_iter': 88.5553, 'accuracy': 0.8652}
val: {'epoch': 45, 'loss': 86.6772, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7093, 'accuracy': 0.0452}
train: {'epoch': 45, 'eta': 11923149.0133, 'loss': 0.431, 'lr': 0.001, 'params': 420100, 'time_iter': 87.3174, 'accuracy': 0.8792}
val: {'epoch': 46, 'loss': 69.8769, 'lr': 0.001, 'params': 420100, 'time_iter': 0.7275, 'accuracy': 0.0441}
train: {'epoch': 46, 'eta': 11702410.7902, 'loss': 0.4788, 'lr': 0.001, 'params': 420100, 'time_iter': 88.3412, 'accuracy': 0.8755}
Results aggregated across runs saved in results_experiments/bottleneck_base_grid_depths_layers_small/bottleneck_base-name=depth_5-batch_size=1024-layers_k2=2-dim_inner=256/agg
