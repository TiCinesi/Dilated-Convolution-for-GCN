GraphGymModule(
  (model): DilatedPositionalGNNModel(
    (encoder): FeatureEncoder(
      (node_encoder): BottleneckEncoder(
        (embedding_list): ModuleList(
          (0): Embedding(9, 256)
          (1): Embedding(9, 256)
        )
      )
    )
    (mp): GNNDilatedPositionalStage(
      (classic_layers): ModuleList(
        (0): GeneralLayer(
          (layer): LayerGINConv(
            (model): GINConv(nn=Sequential(
              (0): Linear(256, 256, bias=True)
              (1): ReLU()
              (2): Linear(256, 256, bias=True)
            ))
          )
          (post_layer): Sequential(
            (0): ReLU()
          )
        )
      )
      (dilated_layers): ModuleList(
        (0): DilatedPositionalGeneralLayer(
          (layer): LayerGINConv(
            (model): GINConv(nn=Sequential(
              (0): Linear(256, 256, bias=True)
              (1): ReLU()
              (2): Linear(256, 256, bias=True)
            ))
          )
          (post_layer): Sequential(
            (0): ReLU()
          )
          (gem): GeM(p=3.0000, eps=1e-06)
          (pos): PositionalEncoding()
        )
        (1): DilatedPositionalGeneralLayer(
          (layer): LayerGINConv(
            (model): GINConv(nn=Sequential(
              (0): Linear(256, 256, bias=True)
              (1): ReLU()
              (2): Linear(256, 256, bias=True)
            ))
          )
          (post_layer): Sequential(
            (0): ReLU()
          )
          (gem): GeM(p=3.0000, eps=1e-06)
          (pos): PositionalEncoding()
        )
      )
      (act): ReLU()
    )
    (post_mp): BottleneckHead(
      (layer_post_mp): Linear(in_features=256, out_features=9, bias=False)
    )
  )
)
accelerator: cuda
benchmark: False
bn:
  eps: 1e-05
  mom: 0.1
cfg_dest: config.yaml
custom_metrics: []
dataset:
  cache_load: False
  cache_save: False
  dir: ./datasets
  edge_dim: 0
  edge_encoder: False
  edge_encoder_bn: False
  edge_encoder_name: Bond
  edge_message_ratio: 0.8
  edge_negative_sampling_ratio: 1.0
  edge_train_mode: all
  encoder: True
  encoder_bn: True
  encoder_dim: 128
  encoder_name: db
  format: BOTTLENECK
  label_column: none
  label_table: none
  location: local
  name: depth_3
  node_encoder: True
  node_encoder_bn: False
  node_encoder_name: bottleneck_encoder
  positional_encoding_path: False
  preprocesss_dataset: True
  remove_feature: False
  resample_disjoint: False
  resample_negative: False
  shuffle_split: True
  split: [0.8, 0.1, 0.1]
  split_mode: random
  task: graph
  task_type: classification
  to_undirected: False
  transductive: False
  transform: none
  tu_simple: True
  use_sparse_adj: False
devices: None
gnn:
  act: relu
  act_on_last_layer_mp: True
  agg: none
  att_final_linear: False
  att_final_linear_bn: False
  att_heads: 4
  att_heads_final: 6
  batchnorm: False
  clear_feature: True
  dilated_path_join: add
  dim_inner: 256
  dropout: 0.0
  edge_agg: add
  head: bottleneck_head
  keep_edge: 0.5
  l2norm: False
  layer_norm: True
  layer_type: ginconv_paper
  layer_type_dilated: ginconv_paper
  layers_k1: 1
  layers_k2: 2
  layers_mp: 3
  layers_post_mp: 1
  layers_pre_mp: 0
  learn_alpha_residual_connection: True
  msg_direction: single
  normalize_adj: False
  self_msg: concat
  skip_every: 1
  stage_type: skipsum
  use_edge_features: False
gpu_mem: False
mem:
  inplace: False
metric_agg: argmax
metric_best: accuracy
model:
  edge_decoding: dot
  graph_pooling: mean
  loss_fun: cross_entropy
  match_upper: True
  size_average: mean
  thresh: 0.5
  type: dilapos_gnn
num_threads: 6
num_workers: 16
optim:
  base_lr: 0.001
  lr_decay: 0.1
  max_epoch: 100
  momentum: 0.9
  optimizer: adam
  scheduler: reduce_lr_on_plateau
  step_gamma: 0.5
  step_size: 10
  steps: [30, 60, 90]
  weight_decay: 0.0
out_dir: results_experiments/bottleneck_base_grid_depths_layers_small/bottleneck_base-name=depth_3-batch_size=1024-layers_k2=2-dim_inner=256
persistent_workers: False
print: both
round: 4
run_dir: results_experiments/bottleneck_base_grid_depths_layers_small/bottleneck_base-name=depth_3-batch_size=1024-layers_k2=2-dim_inner=256/0
seed: 1
share:
  dim0: 8
  dim_in: 2
  dim_out: 8
  num_splits: 2
tensorboard_agg: True
tensorboard_each_run: False
train:
  accumulate_grad: 1
  auto_resume: False
  batch_size: 1024
  ckpt_clean: True
  ckpt_period: 100
  compute_test: False
  early_stopping: True
  early_stopping_patience: 50
  enable_ckpt: True
  epoch_resume: -1
  eval_period: 1
  iter_per_epoch: 32
  monitor_val: False
  neighbor_sizes: [20, 15, 10, 5]
  node_per_graph: 32
  radius: extend
  sample_node: False
  sampler: full_batch
  skip_train_eval: False
  walk_length: 4
train_strategy: None
val:
  node_per_graph: 32
  radius: extend
  sample_node: False
  sampler: full_batch
view_emb: False
Num parameters: 401668
val: {'epoch': 0, 'loss': 2.0818, 'lr': 0.001, 'params': 401668, 'time_iter': 0.465, 'accuracy': 0.1288}
train: {'epoch': 0, 'eta': 455063.3183, 'loss': 2.0869, 'lr': 0.001, 'params': 401668, 'time_iter': 7.3546, 'accuracy': 0.135}
val: {'epoch': 1, 'loss': 1.2276, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4803, 'accuracy': 0.3994}
train: {'epoch': 1, 'eta': 448565.9628, 'loss': 1.6868, 'lr': 0.001, 'params': 401668, 'time_iter': 7.2925, 'accuracy': 0.2658}
val: {'epoch': 2, 'loss': 2.0463, 'lr': 0.001, 'params': 401668, 'time_iter': 0.5956, 'accuracy': 0.4244}
train: {'epoch': 2, 'eta': 452648.5882, 'loss': 0.5404, 'lr': 0.001, 'params': 401668, 'time_iter': 7.7521, 'accuracy': 0.7362}
val: {'epoch': 3, 'loss': 2.7086, 'lr': 0.001, 'params': 401668, 'time_iter': 0.571, 'accuracy': 0.4244}
train: {'epoch': 3, 'eta': 452013.3265, 'loss': 0.2145, 'lr': 0.001, 'params': 401668, 'time_iter': 7.7351, 'accuracy': 0.9079}
val: {'epoch': 4, 'loss': 2.7141, 'lr': 0.001, 'params': 401668, 'time_iter': 0.5923, 'accuracy': 0.4338}
train: {'epoch': 4, 'eta': 445433.8004, 'loss': 0.1743, 'lr': 0.001, 'params': 401668, 'time_iter': 7.376, 'accuracy': 0.9202}
val: {'epoch': 5, 'loss': 2.7954, 'lr': 0.001, 'params': 401668, 'time_iter': 0.5962, 'accuracy': 0.4294}
train: {'epoch': 5, 'eta': 438965.9892, 'loss': 0.16, 'lr': 0.001, 'params': 401668, 'time_iter': 7.3204, 'accuracy': 0.9225}
val: {'epoch': 6, 'loss': 2.8646, 'lr': 0.001, 'params': 401668, 'time_iter': 0.6165, 'accuracy': 0.425}
train: {'epoch': 6, 'eta': 437533.6028, 'loss': 0.1526, 'lr': 0.001, 'params': 401668, 'time_iter': 7.8616, 'accuracy': 0.9236}
val: {'epoch': 7, 'loss': 2.769, 'lr': 0.001, 'params': 401668, 'time_iter': 0.6175, 'accuracy': 0.4381}
train: {'epoch': 7, 'eta': 436006.7543, 'loss': 0.1497, 'lr': 0.001, 'params': 401668, 'time_iter': 7.9696, 'accuracy': 0.9235}
val: {'epoch': 8, 'loss': 2.8961, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4936, 'accuracy': 0.4288}
train: {'epoch': 8, 'eta': 434743.4373, 'loss': 0.1463, 'lr': 0.001, 'params': 401668, 'time_iter': 8.1328, 'accuracy': 0.9239}
val: {'epoch': 9, 'loss': 2.8837, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4691, 'accuracy': 0.4319}
train: {'epoch': 9, 'eta': 428865.1154, 'loss': 0.143, 'lr': 0.001, 'params': 401668, 'time_iter': 7.4481, 'accuracy': 0.9235}
val: {'epoch': 10, 'loss': 2.925, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4757, 'accuracy': 0.425}
train: {'epoch': 10, 'eta': 423027.1856, 'loss': 0.1402, 'lr': 0.001, 'params': 401668, 'time_iter': 7.4121, 'accuracy': 0.9238}
val: {'epoch': 11, 'loss': 2.9735, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4741, 'accuracy': 0.4206}
train: {'epoch': 11, 'eta': 417736.2794, 'loss': 0.1378, 'lr': 0.001, 'params': 401668, 'time_iter': 7.4876, 'accuracy': 0.9235}
val: {'epoch': 12, 'loss': 3.0454, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4731, 'accuracy': 0.4338}
train: {'epoch': 12, 'eta': 412350.901, 'loss': 0.1343, 'lr': 0.001, 'params': 401668, 'time_iter': 7.4426, 'accuracy': 0.9243}
val: {'epoch': 13, 'loss': 3.159, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4699, 'accuracy': 0.4362}
train: {'epoch': 13, 'eta': 407580.9957, 'loss': 0.1324, 'lr': 0.001, 'params': 401668, 'time_iter': 7.5756, 'accuracy': 0.9241}
val: {'epoch': 14, 'loss': 3.1723, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4703, 'accuracy': 0.435}
train: {'epoch': 14, 'eta': 401979.7242, 'loss': 0.1303, 'lr': 0.001, 'params': 401668, 'time_iter': 7.3395, 'accuracy': 0.9245}
val: {'epoch': 15, 'loss': 3.3223, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4859, 'accuracy': 0.4412}
train: {'epoch': 15, 'eta': 396660.2212, 'loss': 0.1283, 'lr': 0.001, 'params': 401668, 'time_iter': 7.3868, 'accuracy': 0.9243}
val: {'epoch': 16, 'loss': 3.4874, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4978, 'accuracy': 0.4425}
train: {'epoch': 16, 'eta': 391512.9757, 'loss': 0.1266, 'lr': 0.001, 'params': 401668, 'time_iter': 7.4161, 'accuracy': 0.9246}
val: {'epoch': 17, 'loss': 3.6058, 'lr': 0.001, 'params': 401668, 'time_iter': 0.474, 'accuracy': 0.4444}
train: {'epoch': 17, 'eta': 385882.0224, 'loss': 0.1259, 'lr': 0.001, 'params': 401668, 'time_iter': 7.2262, 'accuracy': 0.9247}
val: {'epoch': 18, 'loss': 3.6035, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4864, 'accuracy': 0.4556}
train: {'epoch': 18, 'eta': 381650.7919, 'loss': 0.1236, 'lr': 0.001, 'params': 401668, 'time_iter': 7.7075, 'accuracy': 0.9248}
val: {'epoch': 19, 'loss': 3.9417, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4652, 'accuracy': 0.4425}
train: {'epoch': 19, 'eta': 376838.3236, 'loss': 0.1214, 'lr': 0.001, 'params': 401668, 'time_iter': 7.4985, 'accuracy': 0.9249}
val: {'epoch': 20, 'loss': 4.0605, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4596, 'accuracy': 0.4462}
train: {'epoch': 20, 'eta': 372521.4345, 'loss': 0.1229, 'lr': 0.001, 'params': 401668, 'time_iter': 7.7042, 'accuracy': 0.9242}
val: {'epoch': 21, 'loss': 4.1358, 'lr': 0.001, 'params': 401668, 'time_iter': 0.5501, 'accuracy': 0.4256}
train: {'epoch': 21, 'eta': 367914.0741, 'loss': 0.1171, 'lr': 0.001, 'params': 401668, 'time_iter': 7.5935, 'accuracy': 0.9256}
val: {'epoch': 22, 'loss': 4.4679, 'lr': 0.001, 'params': 401668, 'time_iter': 0.5576, 'accuracy': 0.4375}
train: {'epoch': 22, 'eta': 363663.8092, 'loss': 0.1254, 'lr': 0.001, 'params': 401668, 'time_iter': 7.7699, 'accuracy': 0.9228}
val: {'epoch': 23, 'loss': 4.2366, 'lr': 0.001, 'params': 401668, 'time_iter': 0.5252, 'accuracy': 0.4394}
train: {'epoch': 23, 'eta': 358918.7944, 'loss': 0.1149, 'lr': 0.001, 'params': 401668, 'time_iter': 7.5455, 'accuracy': 0.9253}
val: {'epoch': 24, 'loss': 4.3283, 'lr': 0.001, 'params': 401668, 'time_iter': 0.5378, 'accuracy': 0.4312}
train: {'epoch': 24, 'eta': 354361.927, 'loss': 0.1142, 'lr': 0.001, 'params': 401668, 'time_iter': 7.6446, 'accuracy': 0.9254}
val: {'epoch': 25, 'loss': 4.8516, 'lr': 0.001, 'params': 401668, 'time_iter': 0.5371, 'accuracy': 0.4281}
train: {'epoch': 25, 'eta': 350129.9137, 'loss': 0.1244, 'lr': 0.001, 'params': 401668, 'time_iter': 7.8368, 'accuracy': 0.9229}
val: {'epoch': 26, 'loss': 4.8142, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4586, 'accuracy': 0.4431}
train: {'epoch': 26, 'eta': 345436.2835, 'loss': 0.1129, 'lr': 0.001, 'params': 401668, 'time_iter': 7.5928, 'accuracy': 0.9256}
val: {'epoch': 27, 'loss': 5.3336, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4692, 'accuracy': 0.4169}
train: {'epoch': 27, 'eta': 340478.8364, 'loss': 0.1135, 'lr': 0.001, 'params': 401668, 'time_iter': 7.4309, 'accuracy': 0.9252}
val: {'epoch': 28, 'loss': 5.1989, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4597, 'accuracy': 0.4281}
train: {'epoch': 28, 'eta': 335554.204, 'loss': 0.1216, 'lr': 0.001, 'params': 401668, 'time_iter': 7.4383, 'accuracy': 0.9237}
val: {'epoch': 29, 'loss': 5.2306, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4644, 'accuracy': 0.425}
train: {'epoch': 29, 'eta': 330116.5848, 'loss': 0.1114, 'lr': 0.001, 'params': 401668, 'time_iter': 7.0739, 'accuracy': 0.9256}
val: {'epoch': 30, 'loss': 5.9306, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4698, 'accuracy': 0.4306}
train: {'epoch': 30, 'eta': 324605.6544, 'loss': 0.1217, 'lr': 0.001, 'params': 401668, 'time_iter': 6.9741, 'accuracy': 0.9235}
val: {'epoch': 31, 'loss': 5.6597, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4689, 'accuracy': 0.435}
train: {'epoch': 31, 'eta': 319176.4774, 'loss': 0.1109, 'lr': 0.001, 'params': 401668, 'time_iter': 6.9814, 'accuracy': 0.9258}
val: {'epoch': 32, 'loss': 5.6176, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4711, 'accuracy': 0.4312}
train: {'epoch': 32, 'eta': 313856.4465, 'loss': 0.1106, 'lr': 0.001, 'params': 401668, 'time_iter': 7.0165, 'accuracy': 0.9258}
val: {'epoch': 33, 'loss': 6.2315, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4539, 'accuracy': 0.4412}
train: {'epoch': 33, 'eta': 309016.6003, 'loss': 0.121, 'lr': 0.001, 'params': 401668, 'time_iter': 7.367, 'accuracy': 0.923}
val: {'epoch': 34, 'loss': 5.9318, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4713, 'accuracy': 0.4256}
train: {'epoch': 34, 'eta': 304306.7734, 'loss': 0.1114, 'lr': 0.001, 'params': 401668, 'time_iter': 7.4674, 'accuracy': 0.9256}
val: {'epoch': 35, 'loss': 5.568, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4584, 'accuracy': 0.4238}
train: {'epoch': 35, 'eta': 299123.7154, 'loss': 0.1099, 'lr': 0.001, 'params': 401668, 'time_iter': 7.0394, 'accuracy': 0.9258}
val: {'epoch': 36, 'loss': 6.3462, 'lr': 0.001, 'params': 401668, 'time_iter': 0.47, 'accuracy': 0.4212}
train: {'epoch': 36, 'eta': 294214.406, 'loss': 0.1199, 'lr': 0.001, 'params': 401668, 'time_iter': 7.2568, 'accuracy': 0.9237}
val: {'epoch': 37, 'loss': 6.217, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4599, 'accuracy': 0.4262}
train: {'epoch': 37, 'eta': 289356.8995, 'loss': 0.11, 'lr': 0.001, 'params': 401668, 'time_iter': 7.2883, 'accuracy': 0.9258}
val: {'epoch': 38, 'loss': 5.9106, 'lr': 0.001, 'params': 401668, 'time_iter': 0.461, 'accuracy': 0.4206}
train: {'epoch': 38, 'eta': 284291.1623, 'loss': 0.1097, 'lr': 0.001, 'params': 401668, 'time_iter': 7.0594, 'accuracy': 0.9261}
val: {'epoch': 39, 'loss': 6.7979, 'lr': 0.001, 'params': 401668, 'time_iter': 0.5342, 'accuracy': 0.4325}
train: {'epoch': 39, 'eta': 279510.0751, 'loss': 0.1214, 'lr': 0.001, 'params': 401668, 'time_iter': 7.3282, 'accuracy': 0.923}
val: {'epoch': 40, 'loss': 6.493, 'lr': 0.001, 'params': 401668, 'time_iter': 0.5308, 'accuracy': 0.4169}
train: {'epoch': 40, 'eta': 274557.5292, 'loss': 0.1099, 'lr': 0.001, 'params': 401668, 'time_iter': 7.1267, 'accuracy': 0.9253}
val: {'epoch': 41, 'loss': 6.4595, 'lr': 0.001, 'params': 401668, 'time_iter': 0.552, 'accuracy': 0.4269}
train: {'epoch': 41, 'eta': 269908.7554, 'loss': 0.1092, 'lr': 0.001, 'params': 401668, 'time_iter': 7.4511, 'accuracy': 0.9259}
val: {'epoch': 42, 'loss': 6.057, 'lr': 0.001, 'params': 401668, 'time_iter': 0.5515, 'accuracy': 0.4375}
train: {'epoch': 42, 'eta': 265385.3228, 'loss': 0.1149, 'lr': 0.001, 'params': 401668, 'time_iter': 7.6029, 'accuracy': 0.9245}
val: {'epoch': 43, 'loss': 6.9759, 'lr': 0.001, 'params': 401668, 'time_iter': 0.5395, 'accuracy': 0.4319}
train: {'epoch': 43, 'eta': 260751.4422, 'loss': 0.1156, 'lr': 0.001, 'params': 401668, 'time_iter': 7.4771, 'accuracy': 0.9249}
val: {'epoch': 44, 'loss': 6.732, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4723, 'accuracy': 0.4312}
train: {'epoch': 44, 'eta': 256250.2422, 'loss': 0.1093, 'lr': 0.001, 'params': 401668, 'time_iter': 7.653, 'accuracy': 0.9263}
val: {'epoch': 45, 'loss': 7.1408, 'lr': 0.001, 'params': 401668, 'time_iter': 0.5085, 'accuracy': 0.4338}
train: {'epoch': 45, 'eta': 251427.9951, 'loss': 0.1192, 'lr': 0.001, 'params': 401668, 'time_iter': 7.2322, 'accuracy': 0.9235}
val: {'epoch': 46, 'loss': 6.9776, 'lr': 0.001, 'params': 401668, 'time_iter': 0.479, 'accuracy': 0.4244}
train: {'epoch': 46, 'eta': 247085.5314, 'loss': 0.1099, 'lr': 0.001, 'params': 401668, 'time_iter': 7.8947, 'accuracy': 0.9259}
val: {'epoch': 47, 'loss': 6.5943, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4538, 'accuracy': 0.4281}
train: {'epoch': 47, 'eta': 242356.4448, 'loss': 0.1092, 'lr': 0.001, 'params': 401668, 'time_iter': 7.3601, 'accuracy': 0.9259}
val: {'epoch': 48, 'loss': 6.3931, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4624, 'accuracy': 0.415}
train: {'epoch': 48, 'eta': 237445.2906, 'loss': 0.1092, 'lr': 0.001, 'params': 401668, 'time_iter': 7.0721, 'accuracy': 0.9263}
val: {'epoch': 49, 'loss': 7.3742, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4763, 'accuracy': 0.4312}
train: {'epoch': 49, 'eta': 232638.2588, 'loss': 0.12, 'lr': 0.001, 'params': 401668, 'time_iter': 7.2073, 'accuracy': 0.9238}
val: {'epoch': 50, 'loss': 7.0918, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4779, 'accuracy': 0.4369}
train: {'epoch': 50, 'eta': 227890.0745, 'loss': 0.1093, 'lr': 0.001, 'params': 401668, 'time_iter': 7.2855, 'accuracy': 0.9257}
val: {'epoch': 51, 'loss': 6.7286, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4581, 'accuracy': 0.4262}
train: {'epoch': 51, 'eta': 222937.6931, 'loss': 0.1091, 'lr': 0.001, 'params': 401668, 'time_iter': 6.9186, 'accuracy': 0.926}
val: {'epoch': 52, 'loss': 7.5515, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4704, 'accuracy': 0.4319}
train: {'epoch': 52, 'eta': 218074.69, 'loss': 0.1191, 'lr': 0.001, 'params': 401668, 'time_iter': 7.0371, 'accuracy': 0.9238}
val: {'epoch': 53, 'loss': 7.3443, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4666, 'accuracy': 0.4206}
train: {'epoch': 53, 'eta': 213604.1936, 'loss': 0.1093, 'lr': 0.001, 'params': 401668, 'time_iter': 7.742, 'accuracy': 0.926}
val: {'epoch': 54, 'loss': 7.0721, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4725, 'accuracy': 0.4288}
train: {'epoch': 54, 'eta': 208813.9619, 'loss': 0.109, 'lr': 0.001, 'params': 401668, 'time_iter': 7.1429, 'accuracy': 0.9262}
val: {'epoch': 55, 'loss': 6.3228, 'lr': 0.001, 'params': 401668, 'time_iter': 0.4759, 'accuracy': 0.4244}
train: {'epoch': 55, 'eta': 203978.1662, 'loss': 0.109, 'lr': 0.001, 'params': 401668, 'time_iter': 7.0264, 'accuracy': 0.9262}
val: {'epoch': 56, 'loss': 6.7581, 'lr': 0.0005, 'params': 401668, 'time_iter': 0.4751, 'accuracy': 0.4256}
train: {'epoch': 56, 'eta': 199213.1516, 'loss': 0.1084, 'lr': 0.0005, 'params': 401668, 'time_iter': 7.1435, 'accuracy': 0.9261}
val: {'epoch': 57, 'loss': 6.5848, 'lr': 0.0005, 'params': 401668, 'time_iter': 0.4701, 'accuracy': 0.4225}
train: {'epoch': 57, 'eta': 194555.2265, 'loss': 0.1085, 'lr': 0.0005, 'params': 401668, 'time_iter': 7.3572, 'accuracy': 0.9258}
val: {'epoch': 58, 'loss': 7.4236, 'lr': 0.0005, 'params': 401668, 'time_iter': 0.5676, 'accuracy': 0.4288}
train: {'epoch': 58, 'eta': 189876.0147, 'loss': 0.1098, 'lr': 0.0005, 'params': 401668, 'time_iter': 7.3035, 'accuracy': 0.926}
val: {'epoch': 59, 'loss': 7.4431, 'lr': 0.0005, 'params': 401668, 'time_iter': 0.5396, 'accuracy': 0.4175}
train: {'epoch': 59, 'eta': 185237.9508, 'loss': 0.1086, 'lr': 0.0005, 'params': 401668, 'time_iter': 7.3931, 'accuracy': 0.926}
val: {'epoch': 60, 'loss': 7.0841, 'lr': 0.0005, 'params': 401668, 'time_iter': 0.5444, 'accuracy': 0.4175}
train: {'epoch': 60, 'eta': 180557.3424, 'loss': 0.1084, 'lr': 0.0005, 'params': 401668, 'time_iter': 7.2852, 'accuracy': 0.9264}
val: {'epoch': 61, 'loss': 6.9642, 'lr': 0.0005, 'params': 401668, 'time_iter': 0.5493, 'accuracy': 0.4244}
train: {'epoch': 61, 'eta': 175924.6731, 'loss': 0.1084, 'lr': 0.0005, 'params': 401668, 'time_iter': 7.3997, 'accuracy': 0.926}
val: {'epoch': 62, 'loss': 7.4634, 'lr': 0.0005, 'params': 401668, 'time_iter': 0.5378, 'accuracy': 0.4231}
train: {'epoch': 62, 'eta': 171292.0567, 'loss': 0.1105, 'lr': 0.0005, 'params': 401668, 'time_iter': 7.3991, 'accuracy': 0.926}
val: {'epoch': 63, 'loss': 7.3838, 'lr': 0.0005, 'params': 401668, 'time_iter': 0.5412, 'accuracy': 0.415}
train: {'epoch': 63, 'eta': 166614.2927, 'loss': 0.1084, 'lr': 0.0005, 'params': 401668, 'time_iter': 7.27, 'accuracy': 0.9261}
val: {'epoch': 64, 'loss': 7.0462, 'lr': 0.0005, 'params': 401668, 'time_iter': 0.4587, 'accuracy': 0.4169}
train: {'epoch': 64, 'eta': 162058.8229, 'loss': 0.1084, 'lr': 0.0005, 'params': 401668, 'time_iter': 7.6211, 'accuracy': 0.9261}
val: {'epoch': 65, 'loss': 7.3617, 'lr': 0.0005, 'params': 401668, 'time_iter': 0.4741, 'accuracy': 0.4394}
train: {'epoch': 65, 'eta': 157407.9089, 'loss': 0.1104, 'lr': 0.0005, 'params': 401668, 'time_iter': 7.3442, 'accuracy': 0.9261}
val: {'epoch': 66, 'loss': 7.8063, 'lr': 0.0005, 'params': 401668, 'time_iter': 0.4678, 'accuracy': 0.4262}
train: {'epoch': 66, 'eta': 152761.1063, 'loss': 0.1087, 'lr': 0.0005, 'params': 401668, 'time_iter': 7.3517, 'accuracy': 0.9263}
val: {'epoch': 67, 'loss': 8.0177, 'lr': 0.0003, 'params': 401668, 'time_iter': 0.4674, 'accuracy': 0.4231}
train: {'epoch': 67, 'eta': 148134.6999, 'loss': 0.1081, 'lr': 0.0003, 'params': 401668, 'time_iter': 7.4158, 'accuracy': 0.9259}
val: {'epoch': 68, 'loss': 8.0912, 'lr': 0.0003, 'params': 401668, 'time_iter': 0.5288, 'accuracy': 0.4244}
train: {'epoch': 68, 'eta': 143523.7244, 'loss': 0.1081, 'lr': 0.0003, 'params': 401668, 'time_iter': 7.4717, 'accuracy': 0.926}
val: {'epoch': 69, 'loss': 7.9502, 'lr': 0.0003, 'params': 401668, 'time_iter': 0.4839, 'accuracy': 0.4288}
train: {'epoch': 69, 'eta': 139047.5593, 'loss': 0.1081, 'lr': 0.0003, 'params': 401668, 'time_iter': 7.9812, 'accuracy': 0.9261}
val: {'epoch': 70, 'loss': 7.839, 'lr': 0.0003, 'params': 401668, 'time_iter': 0.4695, 'accuracy': 0.4294}
train: {'epoch': 70, 'eta': 134444.1251, 'loss': 0.1081, 'lr': 0.0003, 'params': 401668, 'time_iter': 7.5392, 'accuracy': 0.9259}
val: {'epoch': 71, 'loss': 7.5266, 'lr': 0.0003, 'params': 401668, 'time_iter': 0.4619, 'accuracy': 0.4194}
train: {'epoch': 71, 'eta': 129864.8584, 'loss': 0.1081, 'lr': 0.0003, 'params': 401668, 'time_iter': 7.651, 'accuracy': 0.926}
val: {'epoch': 72, 'loss': 7.6778, 'lr': 0.0003, 'params': 401668, 'time_iter': 0.4777, 'accuracy': 0.4238}
train: {'epoch': 72, 'eta': 125243.96, 'loss': 0.1082, 'lr': 0.0003, 'params': 401668, 'time_iter': 7.495, 'accuracy': 0.9264}
val: {'epoch': 73, 'loss': 7.1252, 'lr': 0.0003, 'params': 401668, 'time_iter': 0.4685, 'accuracy': 0.4344}
train: {'epoch': 73, 'eta': 120595.1789, 'loss': 0.1081, 'lr': 0.0003, 'params': 401668, 'time_iter': 7.3758, 'accuracy': 0.926}
val: {'epoch': 74, 'loss': 7.2407, 'lr': 0.0003, 'params': 401668, 'time_iter': 0.4638, 'accuracy': 0.4262}
train: {'epoch': 74, 'eta': 115955.9233, 'loss': 0.1082, 'lr': 0.0003, 'params': 401668, 'time_iter': 7.4165, 'accuracy': 0.9257}
val: {'epoch': 75, 'loss': 7.4357, 'lr': 0.0003, 'params': 401668, 'time_iter': 0.4666, 'accuracy': 0.4306}
train: {'epoch': 75, 'eta': 111318.2217, 'loss': 0.1082, 'lr': 0.0003, 'params': 401668, 'time_iter': 7.4239, 'accuracy': 0.9264}
val: {'epoch': 76, 'loss': 7.5618, 'lr': 0.0003, 'params': 401668, 'time_iter': 0.5453, 'accuracy': 0.4231}
train: {'epoch': 76, 'eta': 106705.7728, 'loss': 0.1081, 'lr': 0.0003, 'params': 401668, 'time_iter': 7.5595, 'accuracy': 0.9261}
val: {'epoch': 77, 'loss': 7.3577, 'lr': 0.0003, 'params': 401668, 'time_iter': 0.5846, 'accuracy': 0.4262}
train: {'epoch': 77, 'eta': 102117.2738, 'loss': 0.1081, 'lr': 0.0003, 'params': 401668, 'time_iter': 7.7117, 'accuracy': 0.9263}
val: {'epoch': 78, 'loss': 7.6072, 'lr': 0.0001, 'params': 401668, 'time_iter': 0.5858, 'accuracy': 0.4288}
train: {'epoch': 78, 'eta': 97533.612, 'loss': 0.108, 'lr': 0.0001, 'params': 401668, 'time_iter': 7.776, 'accuracy': 0.926}
val: {'epoch': 79, 'loss': 7.6182, 'lr': 0.0001, 'params': 401668, 'time_iter': 0.5778, 'accuracy': 0.425}
train: {'epoch': 79, 'eta': 92912.0709, 'loss': 0.1079, 'lr': 0.0001, 'params': 401668, 'time_iter': 7.5778, 'accuracy': 0.9257}
val: {'epoch': 80, 'loss': 7.6815, 'lr': 0.0001, 'params': 401668, 'time_iter': 0.5916, 'accuracy': 0.4281}
train: {'epoch': 80, 'eta': 88319.1086, 'loss': 0.1079, 'lr': 0.0001, 'params': 401668, 'time_iter': 7.792, 'accuracy': 0.926}
Results aggregated across runs saved in results_experiments/bottleneck_base_grid_depths_layers_small/bottleneck_base-name=depth_3-batch_size=1024-layers_k2=2-dim_inner=256/agg
