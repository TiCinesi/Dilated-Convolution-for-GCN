GraphGymModule(
  (model): DilatedPositionalGNNModel(
    (encoder): FeatureEncoder(
      (node_encoder): BottleneckEncoder(
        (embedding_list): ModuleList(
          (0): Embedding(17, 256)
          (1): Embedding(17, 256)
        )
      )
    )
    (mp): GNNDilatedPositionalStage(
      (classic_layers): ModuleList(
        (0): GeneralLayer(
          (layer): LayerGINConv(
            (model): GINConv(nn=Sequential(
              (0): Linear(256, 256, bias=True)
              (1): ReLU()
              (2): Linear(256, 256, bias=True)
            ))
          )
          (post_layer): Sequential(
            (0): ReLU()
          )
        )
      )
      (dilated_layers): ModuleList(
        (0): DilatedPositionalGeneralLayer(
          (layer): LayerGINConv(
            (model): GINConv(nn=Sequential(
              (0): Linear(256, 256, bias=True)
              (1): ReLU()
              (2): Linear(256, 256, bias=True)
            ))
          )
          (post_layer): Sequential(
            (0): ReLU()
          )
          (gem): GeM(p=3.0000, eps=1e-06)
          (pos): PositionalEncoding()
        )
        (1): DilatedPositionalGeneralLayer(
          (layer): LayerGINConv(
            (model): GINConv(nn=Sequential(
              (0): Linear(256, 256, bias=True)
              (1): ReLU()
              (2): Linear(256, 256, bias=True)
            ))
          )
          (post_layer): Sequential(
            (0): ReLU()
          )
          (gem): GeM(p=3.0000, eps=1e-06)
          (pos): PositionalEncoding()
        )
      )
      (act): ReLU()
    )
    (post_mp): BottleneckHead(
      (layer_post_mp): Linear(in_features=256, out_features=17, bias=False)
    )
  )
)
accelerator: cuda
benchmark: False
bn:
  eps: 1e-05
  mom: 0.1
cfg_dest: config.yaml
custom_metrics: []
dataset:
  cache_load: False
  cache_save: False
  dir: ./datasets
  edge_dim: 0
  edge_encoder: False
  edge_encoder_bn: False
  edge_encoder_name: Bond
  edge_message_ratio: 0.8
  edge_negative_sampling_ratio: 1.0
  edge_train_mode: all
  encoder: True
  encoder_bn: True
  encoder_dim: 128
  encoder_name: db
  format: BOTTLENECK
  label_column: none
  label_table: none
  location: local
  name: depth_4
  node_encoder: True
  node_encoder_bn: False
  node_encoder_name: bottleneck_encoder
  positional_encoding_path: False
  preprocesss_dataset: True
  remove_feature: False
  resample_disjoint: False
  resample_negative: False
  shuffle_split: True
  split: [0.8, 0.1, 0.1]
  split_mode: random
  task: graph
  task_type: classification
  to_undirected: False
  transductive: False
  transform: none
  tu_simple: True
  use_sparse_adj: False
devices: None
gnn:
  act: relu
  act_on_last_layer_mp: True
  agg: none
  att_final_linear: False
  att_final_linear_bn: False
  att_heads: 4
  att_heads_final: 6
  batchnorm: False
  clear_feature: True
  dilated_path_join: add
  dim_inner: 256
  dropout: 0.0
  edge_agg: add
  head: bottleneck_head
  keep_edge: 0.5
  l2norm: False
  layer_norm: True
  layer_type: ginconv_paper
  layer_type_dilated: ginconv_paper
  layers_k1: 1
  layers_k2: 2
  layers_mp: 3
  layers_post_mp: 1
  layers_pre_mp: 0
  learn_alpha_residual_connection: True
  msg_direction: single
  normalize_adj: False
  self_msg: concat
  skip_every: 1
  stage_type: skipsum
  use_edge_features: False
gpu_mem: False
mem:
  inplace: False
metric_agg: argmax
metric_best: accuracy
model:
  edge_decoding: dot
  graph_pooling: mean
  loss_fun: cross_entropy
  match_upper: True
  size_average: mean
  thresh: 0.5
  type: dilapos_gnn
num_threads: 6
num_workers: 16
optim:
  base_lr: 0.001
  lr_decay: 0.1
  max_epoch: 100
  momentum: 0.9
  optimizer: adam
  scheduler: reduce_lr_on_plateau
  step_gamma: 0.5
  step_size: 10
  steps: [30, 60, 90]
  weight_decay: 0.0
out_dir: results_experiments/bottleneck_base_grid_depths_layers_small/bottleneck_base-name=depth_4-batch_size=1024-layers_k2=2-dim_inner=256
persistent_workers: False
print: both
round: 4
run_dir: results_experiments/bottleneck_base_grid_depths_layers_small/bottleneck_base-name=depth_4-batch_size=1024-layers_k2=2-dim_inner=256/0
seed: 1
share:
  dim0: 16
  dim_in: 2
  dim_out: 16
  num_splits: 2
tensorboard_agg: True
tensorboard_each_run: False
train:
  accumulate_grad: 1
  auto_resume: False
  batch_size: 1024
  ckpt_clean: True
  ckpt_period: 100
  compute_test: False
  early_stopping: True
  early_stopping_patience: 50
  enable_ckpt: True
  epoch_resume: -1
  eval_period: 1
  iter_per_epoch: 32
  monitor_val: False
  neighbor_sizes: [20, 15, 10, 5]
  node_per_graph: 32
  radius: extend
  sample_node: False
  sampler: full_batch
  skip_train_eval: False
  walk_length: 4
train_strategy: None
val:
  node_per_graph: 32
  radius: extend
  sample_node: False
  sampler: full_batch
view_emb: False
Num parameters: 407812
val: {'epoch': 0, 'loss': 2.8573, 'lr': 0.001, 'params': 407812, 'time_iter': 0.5143, 'accuracy': 0.0294}
train: {'epoch': 0, 'eta': 3052110.1978, 'loss': 2.7791, 'lr': 0.001, 'params': 407812, 'time_iter': 24.6635, 'accuracy': 0.0764}
val: {'epoch': 1, 'loss': 2.4246, 'lr': 0.001, 'params': 407812, 'time_iter': 0.6868, 'accuracy': 0.2356}
train: {'epoch': 1, 'eta': 3047746.7918, 'loss': 2.3715, 'lr': 0.001, 'params': 407812, 'time_iter': 25.0956, 'accuracy': 0.1945}
val: {'epoch': 2, 'loss': 0.493, 'lr': 0.001, 'params': 407812, 'time_iter': 0.7089, 'accuracy': 0.8319}
train: {'epoch': 2, 'eta': 3045295.4309, 'loss': 0.7761, 'lr': 0.001, 'params': 407812, 'time_iter': 25.5884, 'accuracy': 0.7252}
val: {'epoch': 3, 'loss': 0.5, 'lr': 0.001, 'params': 407812, 'time_iter': 0.5662, 'accuracy': 0.8559}
train: {'epoch': 3, 'eta': 3013553.0218, 'loss': 0.0023, 'lr': 0.001, 'params': 407812, 'time_iter': 25.1043, 'accuracy': 1.0}
val: {'epoch': 4, 'loss': 0.5086, 'lr': 0.001, 'params': 407812, 'time_iter': 0.5332, 'accuracy': 0.8697}
train: {'epoch': 4, 'eta': 2970566.3282, 'loss': 0.0004, 'lr': 0.001, 'params': 407812, 'time_iter': 24.6247, 'accuracy': 1.0}
val: {'epoch': 5, 'loss': 0.5244, 'lr': 0.001, 'params': 407812, 'time_iter': 0.5288, 'accuracy': 0.8725}
train: {'epoch': 5, 'eta': 2929493.1898, 'loss': 0.0001, 'lr': 0.001, 'params': 407812, 'time_iter': 24.5147, 'accuracy': 1.0}
val: {'epoch': 6, 'loss': 0.5315, 'lr': 0.001, 'params': 407812, 'time_iter': 0.5346, 'accuracy': 0.8762}
train: {'epoch': 6, 'eta': 2899960.9445, 'loss': 0.0, 'lr': 0.001, 'params': 407812, 'time_iter': 25.0302, 'accuracy': 1.0}
val: {'epoch': 7, 'loss': 0.5405, 'lr': 0.001, 'params': 407812, 'time_iter': 0.5296, 'accuracy': 0.8781}
train: {'epoch': 7, 'eta': 2868059.897, 'loss': 0.0, 'lr': 0.001, 'params': 407812, 'time_iter': 24.8959, 'accuracy': 1.0}
val: {'epoch': 8, 'loss': 0.5472, 'lr': 0.001, 'params': 407812, 'time_iter': 0.5561, 'accuracy': 0.8825}
train: {'epoch': 8, 'eta': 2835488.7234, 'loss': 0.0, 'lr': 0.001, 'params': 407812, 'time_iter': 24.8292, 'accuracy': 1.0}
val: {'epoch': 9, 'loss': 0.5592, 'lr': 0.001, 'params': 407812, 'time_iter': 0.5438, 'accuracy': 0.8856}
train: {'epoch': 9, 'eta': 2809229.4107, 'loss': 0.0, 'lr': 0.001, 'params': 407812, 'time_iter': 25.3629, 'accuracy': 1.0}
val: {'epoch': 10, 'loss': 0.564, 'lr': 0.001, 'params': 407812, 'time_iter': 0.6308, 'accuracy': 0.8884}
train: {'epoch': 10, 'eta': 2780702.9025, 'loss': 0.0, 'lr': 0.001, 'params': 407812, 'time_iter': 25.2366, 'accuracy': 1.0}
val: {'epoch': 11, 'loss': 0.5721, 'lr': 0.001, 'params': 407812, 'time_iter': 0.6514, 'accuracy': 0.89}
train: {'epoch': 11, 'eta': 2750462.3998, 'loss': 0.0, 'lr': 0.001, 'params': 407812, 'time_iter': 25.1045, 'accuracy': 1.0}
val: {'epoch': 12, 'loss': 0.5822, 'lr': 0.001, 'params': 407812, 'time_iter': 0.6419, 'accuracy': 0.8925}
train: {'epoch': 12, 'eta': 2715910.8174, 'loss': 0.0, 'lr': 0.001, 'params': 407812, 'time_iter': 24.6102, 'accuracy': 1.0}
val: {'epoch': 13, 'loss': 0.5881, 'lr': 0.001, 'params': 407812, 'time_iter': 0.641, 'accuracy': 0.8938}
train: {'epoch': 13, 'eta': 2679467.1689, 'loss': 0.0, 'lr': 0.001, 'params': 407812, 'time_iter': 24.2933, 'accuracy': 1.0}
val: {'epoch': 14, 'loss': 0.593, 'lr': 0.001, 'params': 407812, 'time_iter': 0.5543, 'accuracy': 0.8959}
train: {'epoch': 14, 'eta': 2646734.4248, 'loss': 0.0, 'lr': 0.001, 'params': 407812, 'time_iter': 24.7028, 'accuracy': 1.0}
val: {'epoch': 15, 'loss': 0.595, 'lr': 0.0005, 'params': 407812, 'time_iter': 0.5546, 'accuracy': 0.8972}
train: {'epoch': 15, 'eta': 2614681.0762, 'loss': 0.0, 'lr': 0.0005, 'params': 407812, 'time_iter': 24.771, 'accuracy': 1.0}
val: {'epoch': 16, 'loss': 0.5937, 'lr': 0.0005, 'params': 407812, 'time_iter': 0.524, 'accuracy': 0.8997}
train: {'epoch': 16, 'eta': 2577503.1875, 'loss': 0.0, 'lr': 0.0005, 'params': 407812, 'time_iter': 23.9103, 'accuracy': 1.0}
val: {'epoch': 17, 'loss': 0.588, 'lr': 0.0005, 'params': 407812, 'time_iter': 0.5352, 'accuracy': 0.9034}
train: {'epoch': 17, 'eta': 2536789.9605, 'loss': 0.0, 'lr': 0.0005, 'params': 407812, 'time_iter': 23.1472, 'accuracy': 1.0}
val: {'epoch': 18, 'loss': 1.0615, 'lr': 0.0005, 'params': 407812, 'time_iter': 0.5284, 'accuracy': 0.5731}
train: {'epoch': 18, 'eta': 2503240.8168, 'loss': 0.4733, 'lr': 0.0005, 'params': 407812, 'time_iter': 24.2589, 'accuracy': 0.9287}
val: {'epoch': 19, 'loss': 0.1081, 'lr': 0.0005, 'params': 407812, 'time_iter': 0.5307, 'accuracy': 0.9634}
train: {'epoch': 19, 'eta': 2466298.9025, 'loss': 0.0645, 'lr': 0.0005, 'params': 407812, 'time_iter': 23.5158, 'accuracy': 0.9854}
val: {'epoch': 20, 'loss': 0.0813, 'lr': 0.0005, 'params': 407812, 'time_iter': 0.5626, 'accuracy': 0.9734}
train: {'epoch': 20, 'eta': 2442738.2967, 'loss': 0.0024, 'lr': 0.0005, 'params': 407812, 'time_iter': 26.2086, 'accuracy': 1.0}
val: {'epoch': 21, 'loss': 0.0669, 'lr': 0.0005, 'params': 407812, 'time_iter': 0.6436, 'accuracy': 0.9762}
train: {'epoch': 21, 'eta': 2416071.8631, 'loss': 0.0007, 'lr': 0.0005, 'params': 407812, 'time_iter': 25.6965, 'accuracy': 1.0}
val: {'epoch': 22, 'loss': 0.0575, 'lr': 0.0005, 'params': 407812, 'time_iter': 0.6579, 'accuracy': 0.9788}
train: {'epoch': 22, 'eta': 2387934.1339, 'loss': 0.0003, 'lr': 0.0005, 'params': 407812, 'time_iter': 25.4583, 'accuracy': 1.0}
val: {'epoch': 23, 'loss': 0.0514, 'lr': 0.0005, 'params': 407812, 'time_iter': 0.6603, 'accuracy': 0.9816}
train: {'epoch': 23, 'eta': 2361990.0855, 'loss': 0.0001, 'lr': 0.0005, 'params': 407812, 'time_iter': 26.0901, 'accuracy': 1.0}
val: {'epoch': 24, 'loss': 0.0484, 'lr': 0.0005, 'params': 407812, 'time_iter': 0.5263, 'accuracy': 0.9831}
train: {'epoch': 24, 'eta': 2335475.0809, 'loss': 0.0, 'lr': 0.0005, 'params': 407812, 'time_iter': 26.0801, 'accuracy': 1.0}
val: {'epoch': 25, 'loss': 0.0452, 'lr': 0.0005, 'params': 407812, 'time_iter': 0.5312, 'accuracy': 0.9847}
train: {'epoch': 25, 'eta': 2300991.2261, 'loss': 0.0, 'lr': 0.0005, 'params': 407812, 'time_iter': 23.9717, 'accuracy': 1.0}
val: {'epoch': 26, 'loss': 0.0443, 'lr': 0.0003, 'params': 407812, 'time_iter': 0.5447, 'accuracy': 0.9853}
train: {'epoch': 26, 'eta': 2271966.0578, 'loss': 0.0, 'lr': 0.0003, 'params': 407812, 'time_iter': 25.4879, 'accuracy': 1.0}
val: {'epoch': 27, 'loss': 0.0416, 'lr': 0.0003, 'params': 407812, 'time_iter': 0.5414, 'accuracy': 0.9856}
train: {'epoch': 27, 'eta': 2243086.4964, 'loss': 0.0, 'lr': 0.0003, 'params': 407812, 'time_iter': 25.5962, 'accuracy': 1.0}
val: {'epoch': 28, 'loss': 0.0397, 'lr': 0.0003, 'params': 407812, 'time_iter': 0.5298, 'accuracy': 0.9866}
train: {'epoch': 28, 'eta': 2213185.4858, 'loss': 0.0, 'lr': 0.0003, 'params': 407812, 'time_iter': 25.3326, 'accuracy': 1.0}
val: {'epoch': 29, 'loss': 0.0372, 'lr': 0.0003, 'params': 407812, 'time_iter': 0.6222, 'accuracy': 0.9869}
train: {'epoch': 29, 'eta': 2183970.9191, 'loss': 0.0, 'lr': 0.0003, 'params': 407812, 'time_iter': 25.6083, 'accuracy': 1.0}
val: {'epoch': 30, 'loss': 0.0346, 'lr': 0.0003, 'params': 407812, 'time_iter': 0.8795, 'accuracy': 0.9888}
train: {'epoch': 30, 'eta': 2159304.9694, 'loss': 0.0, 'lr': 0.0003, 'params': 407812, 'time_iter': 27.308, 'accuracy': 1.0}
val: {'epoch': 31, 'loss': 0.0329, 'lr': 0.0003, 'params': 407812, 'time_iter': 0.8371, 'accuracy': 0.9891}
train: {'epoch': 31, 'eta': 2134008.0699, 'loss': 0.0, 'lr': 0.0003, 'params': 407812, 'time_iter': 27.2933, 'accuracy': 1.0}
val: {'epoch': 32, 'loss': 0.0315, 'lr': 0.0003, 'params': 407812, 'time_iter': 0.8854, 'accuracy': 0.9906}
train: {'epoch': 32, 'eta': 2108471.7764, 'loss': 0.0, 'lr': 0.0003, 'params': 407812, 'time_iter': 27.4095, 'accuracy': 1.0}
val: {'epoch': 33, 'loss': 0.0288, 'lr': 0.0003, 'params': 407812, 'time_iter': 1.0228, 'accuracy': 0.9909}
train: {'epoch': 33, 'eta': 2082494.0801, 'loss': 0.0, 'lr': 0.0003, 'params': 407812, 'time_iter': 27.4392, 'accuracy': 1.0}
val: {'epoch': 34, 'loss': 0.0244, 'lr': 0.0003, 'params': 407812, 'time_iter': 0.6972, 'accuracy': 0.9925}
train: {'epoch': 34, 'eta': 2057503.4604, 'loss': 0.0, 'lr': 0.0003, 'params': 407812, 'time_iter': 28.0692, 'accuracy': 1.0}
val: {'epoch': 35, 'loss': 0.0203, 'lr': 0.0003, 'params': 407812, 'time_iter': 0.7431, 'accuracy': 0.9928}
train: {'epoch': 35, 'eta': 2029696.1753, 'loss': 0.0, 'lr': 0.0003, 'params': 407812, 'time_iter': 27.0541, 'accuracy': 1.0}
val: {'epoch': 36, 'loss': 0.0223, 'lr': 0.0003, 'params': 407812, 'time_iter': 0.6903, 'accuracy': 0.9938}
train: {'epoch': 36, 'eta': 2001308.4947, 'loss': 0.1597, 'lr': 0.0003, 'params': 407812, 'time_iter': 26.934, 'accuracy': 0.9764}
val: {'epoch': 37, 'loss': 0.0181, 'lr': 0.0001, 'params': 407812, 'time_iter': 0.7059, 'accuracy': 0.995}
train: {'epoch': 37, 'eta': 1972703.5284, 'loss': 0.0002, 'lr': 0.0001, 'params': 407812, 'time_iter': 26.9638, 'accuracy': 1.0}
val: {'epoch': 38, 'loss': 0.0152, 'lr': 0.0001, 'params': 407812, 'time_iter': 0.7472, 'accuracy': 0.9953}
train: {'epoch': 38, 'eta': 1943598.613, 'loss': 0.0001, 'lr': 0.0001, 'params': 407812, 'time_iter': 26.8418, 'accuracy': 1.0}
val: {'epoch': 39, 'loss': 0.0132, 'lr': 0.0001, 'params': 407812, 'time_iter': 0.7039, 'accuracy': 0.9956}
train: {'epoch': 39, 'eta': 1915037.2584, 'loss': 0.0001, 'lr': 0.0001, 'params': 407812, 'time_iter': 27.2503, 'accuracy': 1.0}
val: {'epoch': 40, 'loss': 0.0115, 'lr': 0.0001, 'params': 407812, 'time_iter': 0.7213, 'accuracy': 0.9956}
train: {'epoch': 40, 'eta': 1885990.8495, 'loss': 0.0001, 'lr': 0.0001, 'params': 407812, 'time_iter': 27.1298, 'accuracy': 1.0}
val: {'epoch': 41, 'loss': 0.01, 'lr': 0.0001, 'params': 407812, 'time_iter': 0.8324, 'accuracy': 0.9962}
train: {'epoch': 41, 'eta': 1856635.2695, 'loss': 0.0, 'lr': 0.0001, 'params': 407812, 'time_iter': 27.085, 'accuracy': 1.0}
val: {'epoch': 42, 'loss': 0.0088, 'lr': 0.0001, 'params': 407812, 'time_iter': 0.8028, 'accuracy': 0.9969}
train: {'epoch': 42, 'eta': 1827444.3449, 'loss': 0.0, 'lr': 0.0001, 'params': 407812, 'time_iter': 27.3107, 'accuracy': 1.0}
val: {'epoch': 43, 'loss': 0.0081, 'lr': 0.0001, 'params': 407812, 'time_iter': 0.8418, 'accuracy': 0.9972}
train: {'epoch': 43, 'eta': 1798577.8162, 'loss': 0.0, 'lr': 0.0001, 'params': 407812, 'time_iter': 27.6559, 'accuracy': 1.0}
val: {'epoch': 44, 'loss': 0.0078, 'lr': 0.0001, 'params': 407812, 'time_iter': 0.7409, 'accuracy': 0.9969}
train: {'epoch': 44, 'eta': 1768913.2868, 'loss': 0.0, 'lr': 0.0001, 'params': 407812, 'time_iter': 27.2995, 'accuracy': 1.0}
val: {'epoch': 45, 'loss': 0.007, 'lr': 0.0001, 'params': 407812, 'time_iter': 0.7044, 'accuracy': 0.9969}
train: {'epoch': 45, 'eta': 1738664.1235, 'loss': 0.0, 'lr': 0.0001, 'params': 407812, 'time_iter': 27.0333, 'accuracy': 1.0}
val: {'epoch': 46, 'loss': 0.0068, 'lr': 0.0001, 'params': 407812, 'time_iter': 0.7308, 'accuracy': 0.9966}
train: {'epoch': 46, 'eta': 1708351.6541, 'loss': 0.0, 'lr': 0.0001, 'params': 407812, 'time_iter': 27.0953, 'accuracy': 1.0}
val: {'epoch': 47, 'loss': 0.0063, 'lr': 0.0001, 'params': 407812, 'time_iter': 0.7142, 'accuracy': 0.9972}
train: {'epoch': 47, 'eta': 1677611.8214, 'loss': 0.0, 'lr': 0.0001, 'params': 407812, 'time_iter': 26.8891, 'accuracy': 1.0}
val: {'epoch': 48, 'loss': 0.0059, 'lr': 0.0001, 'params': 407812, 'time_iter': 0.6972, 'accuracy': 0.9978}
train: {'epoch': 48, 'eta': 1646891.9261, 'loss': 0.0, 'lr': 0.0001, 'params': 407812, 'time_iter': 26.9945, 'accuracy': 1.0}
val: {'epoch': 49, 'loss': 0.0055, 'lr': 0.0001, 'params': 407812, 'time_iter': 0.7206, 'accuracy': 0.9975}
train: {'epoch': 49, 'eta': 1616239.0429, 'loss': 0.0, 'lr': 0.0001, 'params': 407812, 'time_iter': 27.1449, 'accuracy': 1.0}
val: {'epoch': 50, 'loss': 0.0051, 'lr': 0.0001, 'params': 407812, 'time_iter': 0.8355, 'accuracy': 0.9984}
train: {'epoch': 50, 'eta': 1585388.9953, 'loss': 0.0, 'lr': 0.0001, 'params': 407812, 'time_iter': 27.0878, 'accuracy': 1.0}
val: {'epoch': 51, 'loss': 0.0049, 'lr': 0.0001, 'params': 407812, 'time_iter': 0.854, 'accuracy': 0.9984}
train: {'epoch': 51, 'eta': 1554636.3936, 'loss': 0.0, 'lr': 0.0001, 'params': 407812, 'time_iter': 27.2725, 'accuracy': 1.0}
Results aggregated across runs saved in results_experiments/bottleneck_base_grid_depths_layers_small/bottleneck_base-name=depth_4-batch_size=1024-layers_k2=2-dim_inner=256/agg
